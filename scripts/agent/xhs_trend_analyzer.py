"""
AgentæœåŠ¡ - å¼ºåˆ¶é¡ºåºæ‰§è¡Œç‰ˆ
æ ¸å¿ƒç›®æ ‡ï¼šç¦æ­¢å¹¶å‘ï¼Œå¼ºåˆ¶ Agent "æƒ³ä¸€æ­¥ -> èµ°ä¸€æ­¥ -> çœ‹ä¸€æ­¥"ã€‚
"""
from typing import List, Dict, Any, Optional
from config.settings import global_settings
from datetime import datetime, timedelta
import asyncio

# Agno imports
from agno.agent import Agent
from agno.models.dashscope import DashScope
from agno.db.postgres import AsyncPostgresDb
from playwright.async_api import async_playwright

# å¯¼å…¥å¤–éƒ¨ Service
from services.connector_service import ConnectorService
from utils.logger import logger

# 1. æ•°æ®åº“è¿æ¥
db = AsyncPostgresDb(db_url=f"postgresql+asyncpg://{global_settings.database.user}:{global_settings.database.password}@{global_settings.database.host}:{global_settings.database.port}/{global_settings.database.name}")

# 2. æ¨¡å‹é…ç½®
resoning_model = DashScope(
    base_url=global_settings.external_service.aliyun_base_url,
    api_key=global_settings.external_service.aliyun_api_key,
    id="qwen-max-latest", # ä½¿ç”¨æœ€æ–°æ¨¡å‹ä»¥æ›´å¥½åœ°éµå¾ªå¤æ‚æŒ‡ä»¤
)

class XiaohongshuDeepAgent:
    """å°çº¢ä¹¦æ·±åº¦åˆ†æ Agent - é¡ºåºæ‰§è¡Œç‰ˆ"""

    def __init__(
            self,
            source_id: str = "system_user",
            playwright: Any = None,
            keywords: str = None
    ):
        self.connector_service = ConnectorService(source="system", source_id=source_id, playwright=playwright)
        self.keywords = keywords
        self.current_date = datetime.now().strftime("%Y-%m-%d")

        self.agent = Agent(
            name="å°çº¢ä¹¦çˆ†æ¬¾æ¢é’ˆ",
            model=resoning_model,
            tool_call_limit=30, # å¿…é¡»è¶³å¤Ÿå¤§ï¼Œå› ä¸ºé¡ºåºæ‰§è¡Œæ„å‘³ç€äº¤äº’è½®æ•°å˜å¤š
            tools=[
                self.search_xiaohongshu,
                self.get_note_details
            ],
            instructions=[
                f"å½“å‰æ—¥æœŸ: {self.current_date}ã€‚",
                "ä½ çš„ä»»åŠ¡æ˜¯é’ˆå¯¹å…³é”®è¯è¿›è¡Œå¤šç»´åº¦ã€å®æ•ˆæ€§çš„çˆ†æ¬¾æ‹†è§£ã€‚",
                "",
                "## âš ï¸ ä¸¥æ ¼æ‰§è¡Œåè®® (å¿…é¡»éµå®ˆ)",
                "1. **å•çº¿ç¨‹å·¥ä½œæ¨¡å¼**ï¼šä¸ºäº†é˜²æ­¢è§¦å‘åçˆ¬è™«æœºåˆ¶ï¼Œ**ä½ æ¯æ¬¡å›å¤åªèƒ½è°ƒç”¨ã€å”¯ä¸€ã€‘çš„ä¸€ä¸ªå·¥å…·**ã€‚ä¸¥ç¦åœ¨ä¸€æ¬¡å›å¤ä¸­åŒæ—¶ç”³è¯·è°ƒç”¨å¤šä¸ªå·¥å…·ï¼ˆå¦‚åŒæ—¶æœ3ä¸ªè¯ï¼‰ã€‚",
                "2. **é¡ºåºæ‰§è¡Œé€»è¾‘**ï¼š",
                "   - åŠ¨ä½œ Aï¼šè§„åˆ’ç¬¬ 1 ä¸ªå…³é”®è¯ -> è°ƒç”¨æœç´¢ -> ç­‰å¾…ç»“æœè¿”å›ã€‚",
                "   - åŠ¨ä½œ Bï¼šåˆ†æç¬¬ 1 æ¬¡ç»“æœ -> è§„åˆ’ç¬¬ 2 ä¸ªå…³é”®è¯ -> è°ƒç”¨æœç´¢ -> ç­‰å¾…ç»“æœè¿”å›ã€‚",
                "   - åŠ¨ä½œ Cï¼š...ä»¥æ­¤ç±»æ¨ã€‚",
                "",
                "## ä»»åŠ¡æµç¨‹",
                f"1. **å…³é”®è¯è§„åˆ’**ï¼šå›´ç»•ã€Œ{self.keywords}ã€æ„æ€ 3 ä¸ªä¸åŒç»´åº¦çš„æœç´¢è¯ï¼ˆæ ¸å¿ƒè¯ã€åœºæ™¯è¯ã€ç—›ç‚¹è¯ï¼‰ã€‚",
                "2. **è½®è¯¢æœç´¢**ï¼šè¯·**é€ä¸€**å¯¹è¿™ 3 ä¸ªè¯å‘èµ· `search_xiaohongshu`ã€‚",
                "3. **å®æ•ˆæ€§ç­›é€‰**ï¼š",
                "   - é‡ç‚¹å…³æ³¨ `publish_time` åœ¨è¿‘ 7-15 å¤©å†…çš„ç¬”è®°ã€‚",
                "   - å¿½ç•¥ 30 å¤©ä»¥å‰çš„å†…å®¹ã€‚",
                "4. **è¯¦æƒ…æ·±æŒ–**ï¼šæœé›†å®Œæ‰€æœ‰æœç´¢ç»“æœåï¼ŒæŒ‘é€‰ 3-5 ç¯‡æœ€å€¼å¾—åˆ†æçš„ç¬”è®°ï¼Œ**é€ä¸€**æˆ–ä¸€æ¬¡æ€§ï¼ˆä»…æ­¤å¤„å…è®¸æ‰¹é‡ï¼‰è°ƒç”¨ `get_note_details`ã€‚",
                "5. **æœ€ç»ˆæŠ¥å‘Š**ï¼šè¾“å‡º 3 ä¸ªå…·å¤‡å®æ•ˆæ€§çš„çˆ†æ¬¾é€‰é¢˜ã€‚"
            ],
            db=db,
            markdown=True,
            add_history_to_context=True,
            user_id=source_id,
        )

    async def search_xiaohongshu(self, keyword: str, limit: int = 15) -> Dict[str, Any]:
        """
        æœç´¢å°çº¢ä¹¦ã€‚
        """
        try:
            from models.connectors import PlatformType
            logger.info(f"âš¡ï¸ Agent æ­£åœ¨é¡ºåºæ‰§è¡Œæœç´¢: {keyword}")

            # å¯ä»¥åœ¨è¿™é‡Œäººä¸ºåŠ ä¸€ä¸ªçŸ­æš‚ sleepï¼Œç¡®ä¿é¡ºåºæ„Ÿæ›´å¼ºï¼Œä¸”å¯¹å¹³å°æ›´å‹å¥½
            # await asyncio.sleep(2)

            raw_result = await self.connector_service.search_and_extract(
                platform=PlatformType.XIAOHONGSHU,
                keyword=keyword,
                limit=limit
            )

            # æ¸…æ´—æ•°æ®
            cleaned_data = []
            for item in raw_result:
                cleaned_data.append({
                    "note_id": item.get("note_id"),
                    "title": item.get("title"),
                    "liked_count": item.get("liked_count", 0),
                    "publish_time": item.get("publish_time", "æœªçŸ¥"),
                    "full_url": item.get("full_url")
                })

            return {
                "success": True,
                "keyword_current": keyword,
                "status": "æœ¬è½®æœç´¢å®Œæˆï¼Œè¯·åˆ†ææ•°æ®åå†³å®šæ˜¯å¦éœ€è¦æœç´¢ä¸‹ä¸€ä¸ªè¯ã€‚",
                "data": cleaned_data
            }
        except Exception as e:
            return {"success": False, "error": str(e)}

    async def get_note_details(self, urls: List[str]) -> Dict[str, Any]:
        """è·å–ç¬”è®°è¯¦æƒ…"""
        try:
            from models.connectors import PlatformType
            logger.info(f"ğŸ“– Agent æ­£åœ¨é˜…è¯» {len(urls)} ç¯‡ç¬”è®°è¯¦æƒ…...")

            result = await self.connector_service.get_note_details(
                urls=urls,
                platform=PlatformType.XIAOHONGSHU,
                concurrency=3
            )
            return {"success": True, "data": result}
        except Exception as e:
            return {"success": False, "error": str(e)}

    async def analyze_trends_stream(self):
        """æµå¼åˆ†æ"""
        prompt = f"""
        ä»»åŠ¡å¯åŠ¨ï¼šè¯·å¯¹ã€Œ{self.keywords}ã€è¿›è¡Œå¤šç»´åº¦çˆ†æ¬¾æ‹†è§£ã€‚
        
        è¯·è®°ä½ï¼š**ä¸è¦ç€æ€¥ï¼Œä¸€ä¸ªä¸€ä¸ªæœ**ã€‚
        è¯·ç«‹å³å¼€å§‹è§„åˆ’ç¬¬ 1 ä¸ªå…³é”®è¯å¹¶æ‰§è¡Œæœç´¢ã€‚
        """

        async for chunk in self.agent.arun(prompt, stream=True):
            if chunk and chunk.content:
                yield chunk.content

async def main():
    print("=== å°çº¢ä¹¦é¡ºåºæ‰§è¡Œ Agent å¯åŠ¨ ===", flush=True)

    async with async_playwright() as p:
        try:
            analyzer = XiaohongshuDeepAgent(
                source_id="system",
                playwright=p,
                keywords="æµ·è±¹æ–‡åˆ›"
            )

            print(f"[ç›®æ ‡]: {analyzer.keywords} (å¼ºåˆ¶é¡ºåºæ¨¡å¼)")
            print("-" * 60)

            async for content in analyzer.analyze_trends_stream():
                print(content, end="", flush=True)

            print("\n" + "-" * 60)
            print("[ä»»åŠ¡ç»“æŸ]")

        except Exception as e:
            print(f"\næ‰§è¡Œå¼‚å¸¸: {e}")


if __name__ == "__main__":
    asyncio.run(main())